from fastmcp import FastMCP
import pandas as pd
import os
from datetime import datetime
import matplotlib
matplotlib.use("Agg")  # âœ… sem display grÃ¡fico, roda headless
import matplotlib.pyplot as plt

mcp = FastMCP("DataClaw-Local", version="1.0.0")

os.makedirs("outputs", exist_ok=True)
os.makedirs("testes", exist_ok=True)


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# âœ… FIX 2: Limpeza numÃ©rica com regra dos 70%
# Evita destruir colunas de texto como "Cliente_1234" ou "iPhone 15"
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def coerce_numeric_if_majority(series: pd.Series, threshold: float = 0.7) -> pd.Series:
    converted = pd.to_numeric(
        series.astype(str)
            .str.replace(r"[^\d.,\-]", "", regex=True)
            .str.replace(",", "."),
        errors="coerce",
    )
    valid_ratio = converted.notna().sum() / max(len(series), 1)
    return converted if valid_ratio >= threshold else series


def load_csv_robust(file_path: str) -> pd.DataFrame:
    """
    Carrega CSV lidando com todos os problemas BR e sujos.
    âœ… FIX: encoding fallback (utf-8 â†’ latin-1 â†’ cp1252)
    âœ… FIX: separador fallback (; â†’ auto-detect)
    âœ… FIX: limpeza numÃ©rica segura (regra dos 70%)
    """
    file_path = os.path.expanduser(file_path)
    if not os.path.exists(file_path):
        raise FileNotFoundError(f"Arquivo nÃ£o encontrado: {file_path}")

    df = None

    # âœ… FIX 5b: Tenta encodings em sequÃªncia
    for enc in ["utf-8", "latin-1", "cp1252"]:
        try:
            df = pd.read_csv(
                file_path,
                sep=";",
                decimal=",",
                encoding=enc,
                on_bad_lines="skip",
            )
            break
        except (UnicodeDecodeError, Exception):
            continue

    # Fallback: detecÃ§Ã£o automÃ¡tica de separador
    if df is None:
        try:
            df = pd.read_csv(
                file_path,
                sep=None,
                decimal=".",
                encoding="utf-8",
                engine="python",
                on_bad_lines="skip",
            )
        except Exception as e:
            raise ValueError(f"NÃ£o foi possÃ­vel ler o arquivo: {e}")

    # Remove linhas completamente vazias e duplicatas
    df = df.drop_duplicates().dropna(how="all")

    # âœ… FIX 2: Aplica conversÃ£o numÃ©rica segura com threshold 70%
    for col in df.select_dtypes(include="object").columns:
        df[col] = coerce_numeric_if_majority(df[col])

    return df


def detectar_colunas(df: pd.DataFrame):
    """Detecta automaticamente colunas de valor, data e categoria."""
    value_col = next(
        (c for c in df.columns if any(k in c.lower() for k in ["total", "valor", "receita", "faturamento", "preco", "price"])),
        None,
    )
    date_col = next(
        (c for c in df.columns if any(k in c.lower() for k in ["data", "date", "dt_", "_dt", "periodo"])),
        None,
    )
    cat_col = next(
        (c for c in df.columns if any(k in c.lower() for k in ["categoria", "produto", "vendedor", "status", "cidade"])),
        None,
    )
    return value_col, date_col, cat_col


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# TOOL 1: analyze_csv
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
@mcp.tool
def analyze_csv(
    file_path: str,
    pergunta: str = "FaÃ§a uma anÃ¡lise completa: totais, tendÃªncias, outliers e insights acionÃ¡veis",
) -> str:
    """
    Analisa qualquer CSV grande e sujo com precisÃ£o matemÃ¡tica.
    Detecta automaticamente colunas de valor, data e categoria.
    """
    try:
        df = load_csv_robust(file_path)
        value_col, date_col, cat_col = detectar_colunas(df)

        report = f"# ğŸ“Š DataClaw Analysis\n"
        report += f"**Arquivo**: {os.path.basename(file_path)}\n"
        report += f"**Data**: {datetime.now().strftime('%d/%m/%Y %H:%M')}\n"
        report += f"**Linhas**: {len(df):,} | **Colunas**: {len(df.columns)}\n\n"

        # âœ… FIX 5: Resumo estatÃ­stico truncado â€” sÃ³ numÃ©ricas, mÃ¡ximo 8 colunas
        num_df = df.select_dtypes(include="number")
        if not num_df.empty:
            report += "## Resumo EstatÃ­stico\n"
            cols_to_show = num_df.columns[:8].tolist()
            report += num_df[cols_to_show].describe().round(2).to_markdown()
            if len(num_df.columns) > 8:
                report += f"\n*Exibindo {len(cols_to_show)} de {len(num_df.columns)} colunas numÃ©ricas.*\n"
            report += "\n\n"

        # Faturamento total
        if value_col:
            total = df[value_col].sum()
            media = df[value_col].mean()
            maximo = df[value_col].max()
            report += f"## ğŸ’° Financeiro ({value_col})\n"
            report += f"- **Total**: R$ {total:,.2f}\n"
            report += f"- **MÃ©dia por venda**: R$ {media:,.2f}\n"
            report += f"- **Maior venda**: R$ {maximo:,.2f}\n\n"

        # TendÃªncia mensal
        if date_col and value_col:
            df[date_col] = pd.to_datetime(df[date_col], errors="coerce")
            valid_dates = df[date_col].notna()
            report += f"âš ï¸ Datas invÃ¡lidas ignoradas: {(~valid_dates).sum():,} linhas\n\n"
            if valid_dates.sum() > 0:
                monthly = (
                    df[valid_dates]
                    .groupby(df[date_col].dt.to_period("M"))[value_col]
                    .agg(["sum", "count"])
                    .rename(columns={"sum": "Total R$", "count": "Qtd Vendas"})
                    .tail(12)  # Ãºltimos 12 meses
                )
                report += "## ğŸ“… TendÃªncia Mensal (Ãºltimos 12 meses)\n"
                report += monthly.to_markdown() + "\n\n"

        # Top categorias
        if cat_col:
            report += f"## ğŸ·ï¸ Top 10 por {cat_col}\n"
            if value_col:
                top = df.groupby(cat_col)[value_col].sum().sort_values(ascending=False).head(10)
                report += top.to_frame().to_markdown() + "\n\n"
            else:
                top = df[cat_col].value_counts().head(10)
                report += top.to_frame().to_markdown() + "\n\n"

        # Outliers simples
        if value_col:
            q1 = df[value_col].quantile(0.25)
            q3 = df[value_col].quantile(0.75)
            iqr = q3 - q1
            outliers = df[(df[value_col] < q1 - 1.5 * iqr) | (df[value_col] > q3 + 1.5 * iqr)]
            report += f"## âš ï¸ Outliers Detectados\n"
            report += f"- {len(outliers):,} transaÃ§Ãµes fora do padrÃ£o (mÃ©todo IQR)\n"
            if len(outliers) > 0:
                report += f"- Faixa normal: R$ {q1 - 1.5*iqr:,.2f} a R$ {q3 + 1.5*iqr:,.2f}\n\n"

        # Pergunta customizada no relatÃ³rio
        report += f"## ğŸ¤– Pergunta: {pergunta}\n"
        report += "AnÃ¡lise acima responde com dados precisos. Solicite mÃ©tricas especÃ­ficas se necessÃ¡rio.\n\n"

        # âœ… FIX 3: GrÃ¡fico inteligente â€” detecta colunas corretas
        # âœ… FIX 4: Salva arquivo + retorna caminho (nÃ£o base64)
        try:
            plt.figure(figsize=(12, 5))

            if date_col and value_col and valid_dates.sum() > 0:
                monthly["Total R$"].plot(kind="bar", color="steelblue", edgecolor="white")
                plt.title(f"Faturamento Mensal â€” {value_col}", fontsize=14)
                plt.ylabel("R$")
                plt.xlabel("MÃªs")
            elif cat_col and value_col:
                top.plot(kind="barh", color="steelblue", edgecolor="white")
                plt.title(f"Top 10 {cat_col} por {value_col}", fontsize=14)
                plt.xlabel("R$")
            else:
                num_df.mean().plot(kind="bar", color="steelblue", edgecolor="white")
                plt.title("MÃ©dias das colunas numÃ©ricas", fontsize=14)

            plt.tight_layout()
            chart_name = f"chart_{datetime.now().strftime('%Y%m%d_%H%M%S')}.png"
            chart_path = os.path.abspath(f"outputs/{chart_name}")
            plt.savefig(chart_path, dpi=100, bbox_inches="tight")
            plt.close()
            report += f"## ğŸ“ˆ GrÃ¡fico\nSalvo em: `{chart_path}`\n"
        except Exception as chart_err:
            report += f"âš ï¸ GrÃ¡fico nÃ£o gerado: {chart_err}\n"

        return report

    except Exception as e:
        return f"âŒ Erro na anÃ¡lise: {str(e)}\nDica: verifique o caminho do arquivo e se Ã© um CSV vÃ¡lido."


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# TOOL 2: clean_csv
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
@mcp.tool
def clean_csv(file_path: str, output_name: str = "cleaned.csv") -> str:
    """
    Limpa o CSV: remove duplicados, linhas vazias e padroniza encoding.
    Retorna o caminho do arquivo limpo.
    """
    try:
        df_raw = pd.read_csv(file_path, sep=";", decimal=",", encoding="utf-8", on_bad_lines="skip")
        linhas_antes = len(df_raw)

        df_clean = df_raw.drop_duplicates().dropna(how="all").reset_index(drop=True)
        linhas_depois = len(df_clean)

        output_path = os.path.abspath(f"outputs/{output_name}")
        df_clean.to_csv(output_path, index=False, sep=";", decimal=",", encoding="utf-8")

        return (
            f"âœ… CSV limpo salvo em: {output_path}\n"
            f"   Linhas antes: {linhas_antes:,}\n"
            f"   Linhas depois: {linhas_depois:,}\n"
            f"   Removidas: {linhas_antes - linhas_depois:,} (duplicadas/vazias)"
        )
    except Exception as e:
        return f"âŒ Erro na limpeza: {str(e)}"


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# TOOL 3: csv_info  (nova â€” diagnÃ³stico rÃ¡pido)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
@mcp.tool
def csv_info(file_path: str) -> str:
    """
    DiagnÃ³stico rÃ¡pido do CSV: colunas, tipos, % de nulos, encoding.
    Ãštil para entender a estrutura antes de analisar.
    """
    try:
        file_path = os.path.expanduser(file_path)
        # lÃª sÃ³ 1000 linhas para diagnÃ³stico rÃ¡pido
        df = pd.read_csv(file_path, sep=";", decimal=",", encoding="utf-8",
                         nrows=1000, on_bad_lines="skip")

        info = f"# ğŸ” DiagnÃ³stico: {os.path.basename(file_path)}\n\n"
        info += f"**Linhas amostradas**: 1.000 | **Colunas**: {len(df.columns)}\n\n"
        info += "| Coluna | Tipo | % Nulos | Exemplo |\n"
        info += "|--------|------|---------|--------|\n"
        for col in df.columns:
            tipo = str(df[col].dtype)
            pct_nulo = round(df[col].isna().sum() / len(df) * 100, 1)
            exemplo = str(df[col].dropna().iloc[0]) if df[col].notna().any() else "â€”"
            info += f"| {col} | {tipo} | {pct_nulo}% | {exemplo[:30]} |\n"

        return info
    except Exception as e:
        return f"âŒ Erro no diagnÃ³stico: {str(e)}"


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Entry point
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
if __name__ == "__main__":
    print("ğŸš€ DataClaw MCP Local rodando em stdio...")
    print("   Tools disponÃ­veis: analyze_csv | clean_csv | csv_info")
    mcp.run(transport="stdio")